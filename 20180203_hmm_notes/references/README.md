## References

其它分詞器相關的參考資料

* [基于Lucene 的中文分析器分词性能比较研究 from 2011/11 計算機工程](41378658.pdf)
* [自然语言处理基础技术之分词、向量化、词性标注](https://zhuanlan.zhihu.com/p/30354720)
* [HMM演算法](https://tw.saowen.com/a/33e4bdc2fd1e0f55104e8131522b3827455ad178dee088e5f575bb0e78d14654)
* [中文分词工具探析（一）：ICTCLAS (NLPIR)](http://www.cnblogs.com/en-heng/p/6225117.html)
* [开源中文分词工具探析（六）：Stanford CoreNLP](http://www.cnblogs.com/en-heng/p/8428504.html)
  >> CoreNLP的中文分词基于[CRF模型](http://www.cnblogs.com/en-heng/p/6214023.html)
* jieba [DAG无向图中文分词算法](https://hadxu.github.io/2018/01/19/NLP%E4%B9%8B%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95(DAG%E5%9B%BE)%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%AE%9E%E6%88%98/)
* [ansj --詞性說明](https://tw.saowen.com/a/8d888435ddc915b27414b00dbc6ab5a3aa68877de25d79c3ea2497161b6701dc)
* [MMSEG: A Word Identification System for Mandarin Chinese Text Based on Two Variants of the Maximum Matching Algorithm](http://technology.chtsai.org/mmseg/)
* [碼上會！ mmseg4j 中文斷詞java 實作 (55行)](http://function1122.blogspot.tw/2010/10/mmseg4j-java-55.html)

放在 [FB 相關的記錄](https://www.facebook.com/qrtt1?hc_ref=ARSfCOX0wgXTnF3ElDHyDyfg2EHi2RAZJjaiZzxU9hNuD1QkB1i2FlHYIdITLdXdoHI&fref=nf)

* jieba [模型的数据是如何生成的？](https://github.com/fxsjy/jieba/issues/7)
